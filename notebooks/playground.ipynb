{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.ops import unary_union\n",
    "from bc_power import utils, hydro\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import pypsa\n",
    "import numpy as np\n",
    "import atlite\n",
    "import pyomo\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# from pypsa.networkclustering import get_clustering_from_busmap\n",
    "import matplotlib.dates as mdates\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "pyomo.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_pickle = utils.read_pickle(\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/wind.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2021-01-01 00:00:00    136.140320\n",
       "2021-01-01 01:00:00    145.208267\n",
       "2021-01-01 02:00:00    148.262006\n",
       "2021-01-01 03:00:00    148.464341\n",
       "2021-01-01 04:00:00    149.073896\n",
       "                          ...    \n",
       "2021-12-31 19:00:00     65.091729\n",
       "2021-12-31 20:00:00     74.751351\n",
       "2021-12-31 21:00:00     77.994423\n",
       "2021-12-31 22:00:00     83.229626\n",
       "2021-12-31 23:00:00    105.642572\n",
       "Name: BC_QTY_GSS, Length: 8760, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_pickle[\"BC_QTY_GSS\"]['p_max_pu'] * wind_pickle[\"BC_QTY_GSS\"]['p_nom'] # Should be ~142 in spots of (p_max_pu=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging shapely polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/regions/gadm41_CAN_1.json\")\n",
    "mask = gdf['NAME_1'] == \"BritishColumbia\"\n",
    "west_lon = gdf[mask].geometry.bounds['minx'].iloc[0]\n",
    "south_lat = gdf[mask].geometry.bounds['miny'].iloc[0]\n",
    "east_lon = gdf[mask].geometry.bounds['maxx'].iloc[0]\n",
    "north_lat = gdf[mask].geometry.bounds['maxy'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = (west_lon, south_lat, east_lon, north_lat)\n",
    "polygon_1 = shapely.geometry.box(*bbox, ccw=True)\n",
    "\n",
    "bbox_2 = (west_lon-5, south_lat-5, east_lon-5, north_lat-5)\n",
    "polygon_2 = shapely.geometry.box(*bbox_2, ccw=True)\n",
    "\n",
    "polys = [polygon_1, polygon_2]\n",
    "\n",
    "gpd.GeoSeries(polys).boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_lon,south_lat,east_lon ,north_lat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading configuration file and testing extraction of year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = r\"/mnt/c/Users/pmcw9/Delta-E/PICS/PyPSA_BC/config/config.yaml\"\n",
    "cfg = utils.load_config(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_year = cfg['cutout'][\"snapshots\"][\"start\"][0][:4]\n",
    "end_year = cfg['cutout'][\"snapshots\"][\"end\"][0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = cfg['cutout']['path'] + cfg['cutout']['region'][\"name\"]\n",
    "suffix = \"2021\" + \".nc\"\n",
    "\n",
    "\"_\".join([prefix, suffix])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading BC Hydro Load Data and Community Energy and Emissions Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bch = pd.read_csv(\"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/BCH/BalancingAuthorityLoad2020.csv\")\n",
    "ceei_path = \"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/CEEI/bc_utilities_energy_and_emissions_data_at_the_community_level.xlsx\"\n",
    "ceei_bch = pd.read_excel(ceei_path,sheet_name=\"BC Hydro\")\n",
    "ceei_fbc_elec = pd.read_excel(ceei_path,sheet_name=\"FBC Elec\") # Will not use data prior to 2013 otherwise need to pull Kelowna records too\n",
    "ceei_nw = pd.read_excel(ceei_path,sheet_name=\"NewWest\")\n",
    "ceei_nel = pd.read_excel(ceei_path,sheet_name=\"NelsonHydro\")\n",
    "ceei_gf = pd.read_excel(ceei_path,sheet_name=\"GrandForks\")\n",
    "ceei_pen = pd.read_excel(ceei_path,sheet_name=\"Penticton\")\n",
    "ceei_sl = pd.read_excel(ceei_path,sheet_name=\"Summerland\")\n",
    "ceei_prc = pd.read_excel(ceei_path,sheet_name=\"Princeton\")\n",
    "ceei_yk = pd.read_excel(ceei_path,sheet_name=\"YukonElec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_col = \"CONSUMPTION_TOTAL\" # Units of KW-hr\n",
    "ceei_list = [ceei_bch, ceei_fbc_elec, ceei_nw, ceei_nel, ceei_gf, ceei_pen, ceei_sl, ceei_prc, ceei_yk] # ceei_fbc_elec\n",
    "year = 2020\n",
    "tot = 0 # capture total electricity demand in MW-hr for all ELC demands in the dataset\n",
    "for df in ceei_list:\n",
    "    mask = (df['YEAR'] == year) & ((df['ORG_TYPE'] != \"Province\") | (df[\"SOURCE\"] != \"BC Hydro\"))\n",
    "    tot += df[mask][elc_col].sum() / 1000 # convert to MW-hr\n",
    "\n",
    "ratio = bch['Balancing Authority Load'].sum() / tot\n",
    "print(f\"The ratio between the BC Hydro load data and CEEI load is {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bch['Balancing Authority Load']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thermal PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp_path = \"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/SESIT/CODERS/data-pull/supply/generators.csv\"\n",
    "gen_gen_path = \"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/SESIT/CODERS/data-pull/supply/generation_generic.csv\"\n",
    "df = pd.read_csv(tpp_path)\n",
    "gen_params = pd.read_csv(gen_gen_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp_gen_types = {'NG_CT', 'NG_CG', 'NG_CC', 'Gas_CT', 'Oil_CT', \"Coal\", 'Oil_ST', 'Diesel_CT', 'Coal_CCS'}\n",
    "# BC has only NG_CC, NG_CG, NG_CT\n",
    "mask = (df[\"province\"] == \"BC\") & (df[\"gen_type\"].apply(lambda x: x in tpp_gen_types ))\n",
    "tpp = df[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = [\"connecting_node_code\"]\n",
    "sum_list = [\"install_capacity_in_mw\",\"annual_avg_energy_unit_in_gwh/y\"]\n",
    "tpp.groupby(\"connecting_node_code\",group_keys=False).apply(lambda x: utils.merge_assets(x, subset, sum_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp['gen_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params[gen_params['generation_type'] == \"NG_CT\"].iloc[0]['efficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_params.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpp['gen_type']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing conceptual cascade in PyPSA\n",
    "    i) 3 reservoir cascade\n",
    "    ii) testing spill and discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_link_override():\n",
    "    '''\n",
    "    Gets the multi-link override. Needed for cascaded hydroelectric.\n",
    "    '''\n",
    "    # From PyPSA CHP Example: This ensures we can add 2 outputs for a single link i.e bus0 -> bus_1 AND bus_2\n",
    "    override_component_attrs = pypsa.descriptors.Dict(\n",
    "        {k: v.copy() for k, v in pypsa.components.component_attrs.items()}\n",
    "    )\n",
    "    override_component_attrs[\"Link\"].loc[\"bus2\"] = [\n",
    "        \"string\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        \"2nd bus\",\n",
    "        \"Input (optional)\",\n",
    "    ]\n",
    "    override_component_attrs[\"Link\"].loc[\"efficiency2\"] = [\n",
    "        \"static or series\",\n",
    "        \"per unit\",\n",
    "        1.0,\n",
    "        \"2nd bus efficiency\",\n",
    "        \"Input (optional)\",\n",
    "    ]\n",
    "    override_component_attrs[\"Link\"].loc[\"p2\"] = [\n",
    "        \"series\",\n",
    "        \"MW\",\n",
    "        0.0,\n",
    "        \"2nd bus output\",\n",
    "        \"Output\",\n",
    "    ]\n",
    "    return override_component_attrs\n",
    "\n",
    "def get_cascade_network(load_data, **kwargs):\n",
    "    '''\n",
    "    This function is going to replace function above. This function will feature a better design for adding links\n",
    "    and other components when finished.\n",
    "    '''\n",
    "    # setup the network\n",
    "    network = pypsa.Network(override_component_attrs=get_multi_link_override())\n",
    "    network.set_snapshots(range(len(load_data)))\n",
    "    \n",
    "    network.add(\"Bus\", \"elc\", carrier=\"AC\")  # This likely will move\n",
    "    network.add(\"Carrier\", \"water\") # this may move since RoR also has water \n",
    "    network.add(\"Carrier\", \"inflow\", co2_emissions=0.0) # likely will move\n",
    "    network.add(\"Load\", \"elc demand\", bus=\"elc\", p_set=load_data) # likely will move\n",
    "    \n",
    "    for res,components in kwargs.items():\n",
    "        for name,params in components.items():\n",
    "            network.add(**params)\n",
    "\n",
    "    return network\n",
    "\n",
    "def create_reservoir_dict(df, inflow_data, cascade_name=\"demo\"):\n",
    "    '''\n",
    "    Accepts a dataframe of reservoirs and their parameters and\n",
    "    ordering of the the reservoirs. This can be used to create dictionaries\n",
    "    which will be used to instantiate the model of the reservoir.\n",
    "    \n",
    "    Modifications: Likely need to have inflow in csv files which\n",
    "                   can be imported later.\n",
    "    '''\n",
    "    res_dict = {}\n",
    "    for idx,row in df.iterrows():\n",
    "        aid = row['asset_id']\n",
    "        max_inflow = max(inflow_data[aid])\n",
    "        res_dict[aid] = {}\n",
    "        \n",
    "\n",
    "        # 1) add water_bus\n",
    "        res_dict[aid]['water bus'] = {\"class_name\":\"Bus\",\n",
    "                                          \"name\":\" \".join([aid,\"water bus\"]),\n",
    "                                          \"carrier\":\"water\",\n",
    "                                        }\n",
    "\n",
    "        # 2) add reservoir_bus\n",
    "        res_dict[aid]['reservoir bus'] = {\"class_name\":\"Bus\",\n",
    "                                          \"name\":\" \".join([aid,\"reservoir bus\"]),\n",
    "                                          \"carrier\":\"water\",\n",
    "                                        }\n",
    "\n",
    "        # 3) add store_link\n",
    "        res_dict[aid]['store link'] = {\"class_name\":\"Link\",\n",
    "                                       \"name\": \" \".join([aid,\"store link\"]),\n",
    "                                       \"bus0\": res_dict[aid]['water bus']['name'],\n",
    "                                       \"bus1\": res_dict[aid]['reservoir bus']['name'],\n",
    "                                       \"efficiency\":1., # mass balance\n",
    "                                       \"p_nom\":1000000, # FIX: Should be derived to ensure larger than max(inflow + spill + discharge of any upstream reservoirs)\n",
    "                                        } \n",
    "        \n",
    "        # 4) get release_link\n",
    "        res_dict[aid]['release link'] = {\"class_name\":\"Link\",\n",
    "                                       \"name\": \" \".join([aid,\"release link\"]),\n",
    "                                       \"bus0\": res_dict[aid]['reservoir bus']['name'],\n",
    "                                       \"bus1\": res_dict[aid]['water bus']['name'],\n",
    "                                       \"efficiency\":1., # mass_balance\n",
    "                                       \"p_nom\":row[\"s_capacity\"] + row['p_capacity'],\n",
    "                                        } \n",
    "        \n",
    "\n",
    "        # 5) get reservoir store\n",
    "        res_dict[aid]['reservoir store'] = {\"class_name\":\"Store\",\n",
    "                                            \"name\":\" \".join([aid,\"reservoir store\"]),\n",
    "                                            \"bus\":res_dict[aid]['reservoir bus']['name'],\n",
    "                                            \"e_nom\":row[\"r_capacity\"]\n",
    "                                            }\n",
    "        \n",
    "        # 6) add inflow generator\n",
    "        res_dict[aid]['inflow generator'] = {\"class_name\":\"Generator\",\n",
    "                                            \"name\": \" \".join([aid,\"inflow generator\"]),\n",
    "                                            \"bus\": res_dict[aid]['reservoir bus']['name'],\n",
    "                                            \"carrier\": \"inflow\",\n",
    "                                            \"efficiency\":1., # mass_balance\n",
    "                                            \"p_nom\":max_inflow, # max(inflow series)\n",
    "                                            \"p_set\":inflow_data[aid],\n",
    "                                            \"p_max_pu\":[i / max_inflow if i != 0 else 0 for i in inflow_data[aid]],\n",
    "                                            \"p_min_pu\":[i / max_inflow if i != 0 else 0 for i in inflow_data[aid]],\n",
    "                                            } \n",
    "\n",
    "        # Terminal check\n",
    "        if type(row[\"downstream\"]) == str: # not terminal\n",
    "            downstream_aid = \" \".join([row[\"downstream\"],\"water bus\"])\n",
    "        else: # terminal\n",
    "            downstream_aid = \" \".join([cascade_name,\"water exit\"])\n",
    "            # Add bus for the terminal reservoir\n",
    "            res_dict[aid]['terminal bus'] = {\"class_name\":\"Bus\",\n",
    "                                                \"name\":downstream_aid,\n",
    "                                                \"carrier\":\"water\",\n",
    "                                                }\n",
    "            \n",
    "            # Add spill store\n",
    "            res_dict[aid]['terminal store'] = {\"class_name\":\"Store\",\n",
    "                                                \"name\":cascade_name,\n",
    "                                                \"bus\":downstream_aid,\n",
    "                                                \"e_nom\":10000000 # The max storage needs to retain all possible water in the model horizon\n",
    "                                                }\n",
    "\n",
    "        # 7) get discharge link\n",
    "        res_dict[aid]['discharge link'] = {\"class_name\":\"Link\",\n",
    "                                            \"name\": \" \".join([aid,\"discharge link\"]),\n",
    "                                            \"bus0\": res_dict[aid]['water bus']['name'],\n",
    "                                            \"bus1\": row['elc_bus'],\n",
    "                                            \"bus2\": downstream_aid,\n",
    "                                            \"marginal_cost\":0.0001,\n",
    "                                            \"efficiency\":row['p_capacity'] / row['q_rated'], # power conversion \n",
    "                                            \"efficiency2\":1., # mass balance\n",
    "                                            \"p_nom\":row['q_rated'], # Should be derived to ensure larger than max(inflow, spill + discharge)\n",
    "                                            } \n",
    "        # 8) get spill link\n",
    "        res_dict[aid]['spill_link'] = {\"class_name\":\"Link\",\n",
    "                                        \"name\": \" \".join([aid,\"spill link\"]),\n",
    "                                        \"bus0\": res_dict[aid]['water bus']['name'],\n",
    "                                        \"bus1\": downstream_aid,\n",
    "                                        \"efficiency\":1., # mass_balance\n",
    "                                        \"p_nom\":row['s_capacity'], # Should be derived to ensure larger than max(inflow, spill + discharge)\n",
    "                                        }\n",
    "\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_data = [[\"r1\",1,1,10,0,\"r2\",np.nan,\"elc\"],\n",
    "        [\"r2\",1,1,10,0,\"r3\",\"r1\",\"elc\"],\n",
    "        [\"r3\",1,1,10,0,np.nan,\"r2\",\"elc\"]]\n",
    "\n",
    "inflow_data = {\"r1\":[10,10,10],\"r2\":[0,0,0],\"r3\":[0,0,0]} # {\"aid\":[inflow_series], ...}\n",
    "\n",
    "load_data = [1,1,1]\n",
    "\n",
    "# connecting_node_code will need to be added later\n",
    "# upstream doesn't matter other than to find the head reservoir\n",
    "# downstream doesn't matter other than to find the terminal reservoir\n",
    "reservoirs = pd.DataFrame(res_data, columns=[\"asset_id\",\"q_rated\",\"p_capacity\",\"s_capacity\",\"r_capacity\",\"downstream\",\"upstream\",\"elc_bus\"]) \n",
    "res_dict = create_reservoir_dict(reservoirs, inflow_data)\n",
    "network = get_cascade_network(load_data,**res_dict)\n",
    "reservoirs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.lopf(pyomo=False, solver_logfile=\"tester.log\");\n",
    "network.optimize(solver_name='cbc')\n",
    "\n",
    "# create subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1,figsize=(12,8))\n",
    "fig.suptitle('Process variables on conceptual cascade system') \n",
    "# SOC\n",
    "ax_soc = network.stores_t.e.plot(ax=axes[0],marker='o')\n",
    "ax_soc.set_ylabel('State of Charge (SOC) (m^3)')\n",
    "ax_soc.set_title('SOC vs Time')\n",
    "\n",
    "# water discharges\n",
    "col_sel = [\"r1 discharge link\", \"r2 discharge link\", \"r3 discharge link\"]\n",
    "ax_discharge = network.links_t.p0[col_sel].plot(ax=axes[1],marker='o')\n",
    "ax_discharge.set_ylabel('Discharge (MW)')\n",
    "\n",
    "# inflow \n",
    "ax_inflow = network.generators_t.p.plot(ax=axes[2],marker='o')\n",
    "ax_inflow.set_ylabel('Inflow (m^3)')\n",
    "\n",
    "# Formatting\n",
    "ax_inflow.set_xticks([0,1,2])\n",
    "ax_soc.set_xticks([0,1,2])\n",
    "ax_discharge.set_xticks([0,1,2])\n",
    "\n",
    "ax_soc.get_shared_x_axes().join(ax_soc, ax_discharge,ax_inflow)\n",
    "ax_soc.set_xlabel(\"\")\n",
    "ax_discharge.set_xlabel(\"\")\n",
    "ax_soc.set_xticklabels([])\n",
    "ax_discharge.set_xticklabels([])\n",
    "# ax_soc.sharex(ax_soc, ax_discharge,ax_inflow)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Thermal PP in PyPSA\n",
    "    i) Dispatch (check)\n",
    "    ii) Emissions (check) (global)\n",
    "    iii) Ramping (check)\n",
    "    iv) UC (check)\n",
    "    v) Gas-Grid vs no-Grid (check)\n",
    "    vi) ramp_limit_start_up ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tpp_dict(df):\n",
    "    '''\n",
    "    Creates a thermal power plant dictionary that is used to add network components of the thermal powerplants.\n",
    "    '''\n",
    "    tpp_dict = {}\n",
    "    for idx,row in df.iterrows():\n",
    "        aid = row['name']\n",
    "        tpp_dict[aid] = {}\n",
    "        # tpp_dict[aid] = row.to_dict()\n",
    "        # tpp_dict[aid][\"class_name\"] = \"Generator\"\n",
    "\n",
    "        # create link + store representation of generator\n",
    "        bus_name = \" \".join([row['carrier'], \"Bus\"])\n",
    "        tpp_dict[aid]= {\"class_name\":\"Link\",\n",
    "                                    \"name\": \" \".join([aid,\"gen link\"]),\n",
    "                                    \"bus0\": bus_name,\n",
    "                                    \"bus1\": row['bus'],\n",
    "                                    \"carrier\": row['carrier'],\n",
    "                                    \"efficiency\":row['efficiency'],\n",
    "                                    \"ramp_limit_up\":row[\"ramp_limit_up\"],\n",
    "                                    \"ramp_limit_down\":row[\"ramp_limit_down\"],\n",
    "                                    \"p_nom_extendable\":False,\n",
    "                                    \"committable\":row[\"committable\"],\n",
    "                                    \"min_up_time\":row[\"min_up_time\"],\n",
    "                                    \"ramp_limit_start_up\":row[\"ramp_limit_start_up\"],\n",
    "                                    \"ramp_limit_shut_down\":row[\"ramp_limit_shut_down\"],\n",
    "                                    \"p_nom\":row['p_nom'] / row['efficiency'],\n",
    "                                    \"marginal_cost\":row['marginal_cost'], # cost per input unit (Need to be careful when combining fuel cost and variable cost \n",
    "                                    \"p_min_pu\":row['p_min_pu'] # watch out for the forced run condition\n",
    "                                    }\n",
    "        \n",
    "    return tpp_dict\n",
    "\n",
    "def create_tpp_network(load_data,emission_lim, **kwargs):\n",
    "    '''\n",
    "    Creates a thermal powerplant network.\n",
    "    '''\n",
    "    # setup the network\n",
    "    network = pypsa.Network() #(override_component_attrs=get_uc_link_override())\n",
    "    network.set_snapshots(range(len(load_data)))\n",
    "    \n",
    "    # Add carriers\n",
    "    network.add(\"Carrier\", \"co2_emissions\") # likely will move\n",
    "    network.add(\"Carrier\", \"NG\", co2_emissions=1.0) # likely will move (since defined based on infrastructure)\n",
    "\n",
    "    # Add buses\n",
    "    network.add(\"Bus\", \"elc\", carrier=\"AC\")  # This likely will move (since defined based on infrastructure)\n",
    "    network.add(\"Bus\", \"NG Bus\", carrier=\"NG\")\n",
    "\n",
    "    # Add loads\n",
    "    network.add(\"Load\", \"elc demand\", bus=\"elc\", p_set=load_data) # likely will move\n",
    "    \n",
    "    # Add global constraints\n",
    "    network.add(\"GlobalConstraint\",\n",
    "                name=\"co2 constraint\",\n",
    "                sense=\"<=\",\n",
    "                carrier_attribute=\"co2_emissions\",\n",
    "                constant=emission_lim)\n",
    "\n",
    "    e_fill = 10000\n",
    "    network.add(class_name=\"Store\",\n",
    "                name=\"NG store\",\n",
    "                bus=\"NG Bus\",\n",
    "                # e_nom_min=-float(\"inf\"),\n",
    "                # e_nom_max=0,\n",
    "                e_nom=e_fill,\n",
    "                e_initial=e_fill,\n",
    "                # e_nom_extendable=True,\n",
    "                # e_min_pu=1.0,\n",
    "                # e_max_pu=0.0\n",
    "    )\n",
    "    \n",
    "    # link store based\n",
    "    for tpp,params in kwargs.items():\n",
    "        network.add(**params)\n",
    "\n",
    "    # generator based\n",
    "    # for tpp,params in kwargs.items():\n",
    "    #     network.add(**params)\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tpp_data = [['NG_CC', 'elc', 10, 'NG', 10, 0.4, False, 1, 1, 1, 0.2, 0.2],\n",
    "#             ['NG_CT', 'elc', 10, 'NG', 10, 0.8, False, 1, 1, 1, 0.2, 0.2],\n",
    "#             ['NG_CG', 'elc', 10, 'NG', 10, 0.7, False, 1, 1, 1, 0.2, 0.2]]\n",
    "tpp_data = [['NG_CT', 'elc', 20, 'NG', 5, 1, False, 25, 1, 1, 0.5, 1, 1, 1, 0], \n",
    "            ['NG_CC', 'elc', 20, 'NG', 10, 1, False, 25, 1, 1, 1, 1, 1, 1, 0]] # Swap 0 -> 10\n",
    "tpp = pd.DataFrame(tpp_data, columns=['name','bus','p_nom','carrier','marginal_cost','efficiency','committable','start_up_cost','min_up_time','min_down_time','ramp_limit_up','ramp_limit_down','ramp_limit_start_up','ramp_limit_shut_down', \"p_min_pu\"])\n",
    "tpp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = [10, 25, 20] # [10, 15, 9, 15, 15]\n",
    "emission_lim = 10000 # Model horizon\n",
    "\n",
    "# ramp limit still has not been added\n",
    "\n",
    "tpp_dict = create_tpp_dict(tpp)\n",
    "network = create_tpp_network(load_data,emission_lim, **tpp_dict)\n",
    "# m = network.optimize.create_model()\n",
    "# m.solve(solver_name=\"glpk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.optimize(solver_name='cbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links_t.mu_ramp_limit_up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRE concept in PyPSA\n",
    "    i) Generation (check)\n",
    "    ii) Snapshots (check)\n",
    "    iii) investments (check)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vre_network(vre_ts,load_ts,vre_dict):\n",
    "    '''\n",
    "    Adds a generator to a bus with a time varying load.\n",
    "    '''\n",
    "    # setup the network\n",
    "    network = pypsa.Network()\n",
    "    network.set_snapshots(load_ts.index)\n",
    "\n",
    "    # Add buses\n",
    "    network.add(\"Bus\", \"elc\", carrier=\"AC\")  # This likely will move (since defined based on infrastructure)\n",
    "    network.add(\"Carrier\", \"NG\")\n",
    "    # Add loads\n",
    "    network.add(\"Load\", \"elc demand\", bus=\"elc\", p_set=load_ts) # likely will move\n",
    "    \n",
    "    # Add base/peaking generator\n",
    "    network.add(class_name=\"Generator\",\n",
    "                name=\"Filler\",\n",
    "                bus=\"elc\",\n",
    "                p_nom=10,\n",
    "                carrier=\"NG\",\n",
    "                marginal_cost=10)\n",
    "\n",
    "    for name,params in vre_dict.items():\n",
    "        network.add(**params)\n",
    "\n",
    "    return network\n",
    "\n",
    "\n",
    "def create_vre_dict(vre,vre_ts_dict):\n",
    "    '''\n",
    "    Returns a vre_dict\n",
    "    '''\n",
    "    vre_dict = {}\n",
    "    for idx,row in vre.iterrows():\n",
    "        vre_dict[row[\"name\"]] = {\"class_name\":row[\"class_name\"],\n",
    "                                 \"name\":row[\"name\"],\n",
    "                                 \"bus\":row[\"bus\"],\n",
    "                                 \"p_nom\":row[\"p_nom\"],\n",
    "                                 \"marginal_cost\":row[\"marginal_cost\"],\n",
    "                                 \"p_nom_extendable\":row[\"p_nom_extendable\"],\n",
    "                                 \"capital_cost\":row[\"capital_cost\"],\n",
    "                                 \"p_max_pu\":vre_ts_dict[row[\"name\"]]}\n",
    "        \n",
    "\n",
    "    return vre_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create snapshots\n",
    "time = pd.date_range('2021-01-01 00:00:00', '2021-01-02 00:00:00', freq='1H', inclusive='left')\n",
    "\n",
    "# calculation vre\n",
    "t = np.linspace(0, 2*np.pi, len(time))\n",
    "y = abs(np.sin(t)) \n",
    "load_ts = pd.Series([3]*len(time),index=time)\n",
    "vre_ts = pd.Series(y, index=time)\n",
    "vre_ts_dict = {}\n",
    "vre_ts_dict[\"sol_generation\"] = vre_ts\n",
    "\n",
    "# create vre df\n",
    "vre_data = [[\"Generator\", \"sol_generation\", \"elc\", 0, 0.0001, True, 50]]\n",
    "vre = pd.DataFrame(vre_data, columns=[\"class_name\",'name','bus','p_nom',\"marginal_cost\",\"p_nom_extendable\",\"capital_cost\"])\n",
    "vre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vre_dict = create_vre_dict(vre,vre_ts_dict)\n",
    "network = create_vre_network(vre_ts, load_ts, vre_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vre_ts * 7.5301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.generators_t.p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing generator with multi-output\n",
    "Fixing the WHN, WAN, and WDN hydroelectric stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_link_override():\n",
    "    '''\n",
    "    Gets the multi-link override. Needed for cascaded hydroelectric.\n",
    "    '''\n",
    "    # From PyPSA CHP Example: This ensures we can add 2 outputs for a single link i.e bus0 -> bus_1 AND bus_2\n",
    "    override_component_attrs = pypsa.descriptors.Dict(\n",
    "        {k: v.copy() for k, v in pypsa.components.component_attrs.items()}\n",
    "    )\n",
    "    override_component_attrs[\"Link\"].loc[\"bus2\"] = [\n",
    "        \"string\",\n",
    "        np.nan,\n",
    "        np.nan,\n",
    "        \"2nd bus\",\n",
    "        \"Input (optional)\",\n",
    "    ]\n",
    "    override_component_attrs[\"Link\"].loc[\"efficiency2\"] = [\n",
    "        \"static or series\",\n",
    "        \"per unit\",\n",
    "        1.0,\n",
    "        \"2nd bus efficiency\",\n",
    "        \"Input (optional)\",\n",
    "    ]\n",
    "    override_component_attrs[\"Link\"].loc[\"p2\"] = [\n",
    "        \"series\",\n",
    "        \"MW\",\n",
    "        0.0,\n",
    "        \"2nd bus output\",\n",
    "        \"Output\",\n",
    "    ]\n",
    "    return override_component_attrs\n",
    "\n",
    "def get_ror_water_dict(ror_water_dict, ror_p_series):\n",
    "    '''\n",
    "    Creates a custom run of river asset for pypsa which is comprised of multiple assets.\n",
    "    This is done to track water \n",
    "    '''\n",
    "    aid = \"BC_XXX_GSS\"\n",
    "    up_rid= \"RID_up\"\n",
    "    down_rid = \"RID_down\"\n",
    "    carrier = \"water\"\n",
    "\n",
    "    # (1) Add reservoir bus where the inflow generators is attached too\n",
    "    # carrier = \"Water\"\n",
    "    class_name = \"Bus\"\n",
    "    ror_water_dict[\"reservoir bus\"] = {\"class_name\":class_name,\n",
    "                                        \"name\":\" \".join([up_rid,carrier,class_name]),\n",
    "                                        \"carrier\":carrier,\n",
    "                                        }\n",
    "\n",
    "    # (2) Add inflow generator\n",
    "    class_name = \"Generator\"\n",
    "    max_energy = ror_p_series.max()\n",
    "    ror_water_dict['inflow generator'] = {\"class_name\":class_name,\n",
    "                                            \"name\": \" \".join([up_rid,\"Inflow\",class_name]),\n",
    "                                            \"bus\": ror_water_dict['reservoir bus']['name'],\n",
    "                                            \"carrier\": \"inflow\",\n",
    "                                            \"efficiency\":1., # mass_balance\n",
    "                                            \"p_nom\":max_energy, # max(inflow series)\n",
    "                                            \"p_set\":ror_p_series,\n",
    "                                            \"p_max_pu\":[flow / max_energy if flow != 0 else 0 for flow in ror_p_series],\n",
    "                                            \"p_min_pu\":[flow / max_energy if flow != 0 else 0 for flow in ror_p_series],\n",
    "                                            }\n",
    "    \n",
    "    # (3) add discharge link\n",
    "    ## ADD code here to grab ELC bus based on the connecting_node_code\n",
    "    elc_bus_name = \"Electrical\" #utils.get_gen_bus(site[\"connecting_node_code\"], bus_dict)\n",
    "    class_name = \"Link\"\n",
    "    # Need to use conversion factor to convert RoR Power series to water discharges.\n",
    "    site_capacity = 5 # MW\n",
    "    q_rated = 10 # Units of m^3 / hr\n",
    "    eff_mwhr_to_m3 = q_rated / site_capacity # site['capacity'] / q_rated\n",
    "    marginal_cost = 1 # (site[\"variable_om_cost_USD_per_MWh\"] + 2) * efficiency_convesion\n",
    "\n",
    "    downstream_bus = \" \".join([down_rid, carrier, class_name])\n",
    "\n",
    "\n",
    "    ror_water_dict['discharge link'] = {\"class_name\":class_name,\n",
    "                                    \"name\": \" \".join([aid,\"Discharge Link\"]),\n",
    "                                    \"bus0\": ror_water_dict['reservoir bus']['name'], # res bus\n",
    "                                    \"bus1\": elc_bus_name, # elc bus\n",
    "                                    \"bus2\": downstream_bus, # downstream res\n",
    "                                    \"marginal_cost\":marginal_cost,\n",
    "                                    \"efficiency\":1.0,  # energy balance\n",
    "                                    \"efficiency2\":eff_mwhr_to_m3, # energy to water\n",
    "                                    \"p_nom\":site_capacity, # Should be derived to ensure larger than max(inflow, spill + discharge)\n",
    "                                    } \n",
    "    \n",
    "    class_name = \"Link\"\n",
    "    \n",
    "    ror_water_dict['spill link'] = {\"class_name\":class_name,\n",
    "                                    \"name\": \" \".join([aid,\"Spill Link\"]),\n",
    "                                    \"bus0\": ror_water_dict['reservoir bus']['name'], # res bus\n",
    "                                    \"bus1\": downstream_bus, # downstream res\n",
    "                                    \"marginal_cost\":marginal_cost,\n",
    "                                    \"efficiency\":eff_mwhr_to_m3, # energy to water\n",
    "                                    \"p_nom\":100, # Should be derived to ensure larger than max(inflow, spill + discharge)\n",
    "                                    } \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pypsa.Network(override_component_attrs=get_multi_link_override())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create snapshots\n",
    "time = pd.date_range('2021-01-01 00:00:00', '2021-01-02 00:00:00', freq='1H', inclusive='left')\n",
    "\n",
    "# Calculation VRE\n",
    "t = np.linspace(0, 2*np.pi, len(time))\n",
    "y = abs(np.sin(t)) + 3\n",
    "\n",
    "\n",
    "vre_ts = pd.Series(y, index=time)\n",
    "# vre_ts_dict = {}\n",
    "# vre_ts_dict[\"sol_generation\"] = vre_ts\n",
    "\n",
    "# load calc\n",
    "load_ts = pd.Series([2]*len(time),index=time)\n",
    "\n",
    "# Add snapashots to network\n",
    "network.set_snapshots(load_ts.index)\n",
    "\n",
    "# Add water carrier\n",
    "network.add(\"Carrier\", \"Water\")\n",
    "\n",
    "# Add buses\n",
    "network.add(\"Bus\", \"Electrical\", carrier=\"AC\")  # This likely will move (since defined based on infrastructure)\n",
    "# network.add(\"Bus\", \"water\", carrier=\"water\")\n",
    "network.add(\"Bus\", \"RID_down water Link\", carrier=\"water\")\n",
    "\n",
    "# Add store \n",
    "network.add(\"Store\",\n",
    "            name = \"Temp Cascade\",\n",
    "            bus =\"RID_down water Link\",\n",
    "            e_nom=1e30)\n",
    "# Add loads\n",
    "network.add(\"Load\", \"elc demand\", bus=\"Electrical\", p_set=load_ts) # Likely will move\n",
    "\n",
    "\n",
    "# Add genertors\n",
    "ror_water_dict = {}\n",
    "ror_p_series = y\n",
    "get_ror_water_dict(ror_water_dict, ror_p_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ror with water accounting to model\n",
    "for name,params in ror_water_dict.items():\n",
    "        network.add(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.links_t.p0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test running network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_comp_in_network(comp,network):\n",
    "    '''\n",
    "    This function checks to see whether a component has been added already or not.\n",
    "    '''\n",
    "    if comp['class_name'] == 'Bus':\n",
    "        return comp['name'] in network.buses.index\n",
    "    if comp['class_name'] == 'Link':\n",
    "        return comp['name'] in network.links.index\n",
    "    if comp['class_name'] == 'Store':\n",
    "        return comp['name'] in network.stores.index\n",
    "    if comp['class_name'] == 'Generator':\n",
    "        return comp['name'] in network.generators.index\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = pypsa.Network(override_component_attrs=utils.get_multi_link_override())\n",
    "path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-network\"\n",
    "hydro_ror_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/hydro_ror.pickle\"\n",
    "hydro_res_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/hydro_reservoirs.pickle\"\n",
    "wind_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/wind_farms.pickle\"\n",
    "pv_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/pv.pickle\"\n",
    "tpp_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-components/tpp.pickle\"\n",
    "network.import_from_csv_folder(path)\n",
    "ror_dict = utils.read_pickle(hydro_ror_path)\n",
    "res_dict = utils.read_pickle(hydro_res_path)\n",
    "wind_dict = utils.read_pickle(wind_path)\n",
    "pv_dict = utils.read_pickle(pv_path)\n",
    "tpp_dict = utils.read_pickle(tpp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set timeslicing structure for the problem\n",
    "network.set_snapshots(ror_dict['BC_ABN_GSS']['p_max_pu'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add RoR assets to the mode\n",
    "for ror in ror_dict.values():\n",
    "    network.add(**ror)\n",
    "\n",
    "# Add Reservoir assets to the model\n",
    "for res_comps in res_dict.values():\n",
    "    for comp in res_comps.values():\n",
    "        if not is_comp_in_network(comp,network): # Avoid duplicate error\n",
    "            network.add(**comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wind farms\n",
    "for comp in wind_dict.values():\n",
    "    network.add(**comp)\n",
    "\n",
    "# add pv asset\n",
    "for comp in pv_dict.values():\n",
    "    network.add(**comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add tpp\n",
    "for comp in tpp_dict.values():\n",
    "    network.add(**comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_ts = ror_dict['BC_ABN_GSS']['p_max_pu'] * 2\n",
    "# network.add(\"Load\", \"elc demand\", bus=\"138_LMN_GSS\", p_set=load_ts)\n",
    "network.add(\"Carrier\",\"NG\", co2_emissions=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = network.optimize.create_model()\n",
    "# model.constraints[\"Link-fix-p-lower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.optimize(solver_name='cbc') # Running all nodes in BC... (Big problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in buses\n",
    "# Used to find buses which need to be clusterd (i.e. only electrical buses included in the clustering)\n",
    "bus_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/pypsa-network/buses.csv\"\n",
    "bus_dict = {name:0 for name in pd.read_csv(bus_path)['name'].tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"C:\\Users\\pmcw9\\Delta-E\\PICS\\Data\\regions\\gadm41_CAN_2.json\"\n",
    "geojson_file = \"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/regions/gadm41_CAN_2.json\"\n",
    "gdf = gpd.read_file(geojson_file)\n",
    "\n",
    "# Get GeoDataFrame of the GADM regions.\n",
    "gadm_bc = gdf[gdf[\"NAME_1\"] ==\"BritishColumbia\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Determine mapping between buses and GADM_region\n",
    "# Determine which buses line within which gadm regions\n",
    "# output: {bus:GADM_region, ...} \n",
    "busmap_dict = {}\n",
    "for bus,row in network.buses.iterrows(): # Loop over buses\n",
    "    point = Point((row['x'],row['y']))\n",
    "    for idx, row in gadm_bc.iterrows():\n",
    "        if row.geometry.contains(point): # Check to see which GADM region is in contained within\n",
    "            busmap_dict[bus] = row[\"NAME_2\"]\n",
    "            break\n",
    "\n",
    "\n",
    "# busmap = pd.Series(busmap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Create a new bus for GADM regions which have been mapped\n",
    "for gadm_region in busmap_dict.values(): \n",
    "    if gadm_region not in network.buses.index.to_list():\n",
    "        # Could also use a dictionary to provide these values\n",
    "        network.add(class_name=\"Bus\",\n",
    "                    name=gadm_region,\n",
    "                    x=gadm_bc[gadm_bc[\"NAME_2\"] == gadm_region].geometry.centroid.x.iloc[0],\n",
    "                    y=gadm_bc[gadm_bc[\"NAME_2\"] == gadm_region].geometry.centroid.y.iloc[0],\n",
    "                    v_nom = 300\n",
    "                    )\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# gadm_bc.plot(ax=ax)\n",
    "# for idx in range(28):\n",
    "#     ax.scatter(gadm_bc.iloc[idx].geometry.centroid.x,gadm_bc.iloc[idx].geometry.centroid.y,color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_bus_refs(component,col, busmap_dict):\n",
    "    mask = component[col].isin(busmap_dict.keys())\n",
    "    component.loc[mask,col] = component.loc[mask,col].map(busmap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Determine all components to relink\n",
    "# i) Find links and generators which have matching buses somewhere and replace them with gadm_region as the new bus\n",
    "replace_bus_refs(network.generators,'bus', busmap_dict)\n",
    "replace_bus_refs(network.links,'bus0', busmap_dict)\n",
    "replace_bus_refs(network.links,'bus1', busmap_dict)\n",
    "replace_bus_refs(network.links,'bus2', busmap_dict)\n",
    "replace_bus_refs(network.lines,'bus0', busmap_dict)\n",
    "replace_bus_refs(network.lines,'bus1', busmap_dict)\n",
    "replace_bus_refs(network.loads,'bus', busmap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) remove old buses,  remove lines inside a new node\n",
    "\n",
    "# (i) Remove interior lines to new nodes/buses\n",
    "lines_to_remove = []\n",
    "for line_name,row in network.lines.iterrows():\n",
    "    if row['bus0'] == row['bus1']:\n",
    "        lines_to_remove.append(line_name)\n",
    "\n",
    "for line_name in lines_to_remove:\n",
    "    network.remove(class_name='Line',name=line_name)\n",
    "\n",
    "# (ii) Remove old buses\n",
    "for bus_name in busmap_dict.keys():\n",
    "    network.remove(class_name='Bus',name=bus_name)\n",
    "\n",
    "\n",
    "# (iii) remove transformers\n",
    "trans_to_remove = []\n",
    "for trans_name,row in network.transformers.iterrows():\n",
    "    trans_to_remove.append(trans_name)\n",
    "\n",
    "for trans_name in trans_to_remove:\n",
    "    network.remove(class_name='Transformer',name=trans_name)\n",
    "\n",
    "# NOTE: Custom revmoval of Site C\n",
    "# Will need to be updated\n",
    "network.remove(class_name='Link', name='BC_STC_GSS Discharge Link')\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) Add load_ts to the \n",
    "# NOTE: Load needs to be permanently scaled to MW-hr rather than KW-hr\n",
    "config_file = r\"/home/pmcwhannel/repos/PyPSA_BC/config/config.yaml\"\n",
    "cfg = utils.load_config(config_file)\n",
    "\n",
    "start_time = cfg['scope']['temporal']['start'] \n",
    "end_time = cfg['scope']['temporal']['end']\n",
    "\n",
    "res_load = pd.read_csv(r\"/home/pmcwhannel/repos/PyPSA_BC/results/hourly_res.csv\", index_col=0, parse_dates=True).loc[start_time:end_time]\n",
    "csmi_load = pd.read_csv(r\"/home/pmcwhannel/repos/PyPSA_BC/results/hourly_csmi.csv\", index_col=0, parse_dates=True).loc[start_time:end_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_ts = ror_dict['BC_ABN_GSS']['p_max_pu'] * 2\n",
    "# network.add(\"Load\", \"elc demand\", bus=\"138_LMN_GSS\", p_set=load_ts)\n",
    "for col in res_load.columns:\n",
    "    if col not in [\"Stikine\", \"CentralCoast\", \"NorthernRockies\"]:\n",
    "        load_ts= res_load[col] + csmi_load[col]\n",
    "        network.add(\"Load\", \"{} ELC Load\".format(col), bus=col, p_set=load_ts)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.lines['s_nom'] = 12000 # Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.optimize(solver_name='cbc') # \n",
    "network.export_to_netcdf(cfg[\"pypsa\"][\"results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.links.index.str.contains('MCA')\n",
    "# network.links[network.links.index.str.contains('MCA')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_region(network,link_name):\n",
    "    return network.links.loc[link_name].bus1\n",
    "\n",
    "def get_gen_region(network,gen_name):\n",
    "    return network.generators.loc[gen_name].bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Find reservoir power production aggregate for all regions and timeslices\n",
    "res_link_names = network.links_t.p1.columns[network.links_t.p1.columns.str.contains('Discharge Link')].to_list()\n",
    "\n",
    "res_region_p_dict = {}\n",
    "for link_name in res_link_names:\n",
    "    region_name = get_link_region(network, link_name)\n",
    "    if region_name not in res_region_p_dict.keys():\n",
    "        res_region_p_dict[region_name] = network.links_t.p1[link_name].apply(lambda x: abs(x))\n",
    "    else:\n",
    "        res_region_p_dict[region_name] += network.links_t.p1[link_name].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) Find RoR Power production for\n",
    "ror_names = network.generators_t.p_max_pu.columns[network.generators_t.p_max_pu.columns.str.contains('RoR Generator')].to_list()\n",
    "\n",
    "ror_region_p_dict = {}\n",
    "for gen_name in ror_names :\n",
    "    region_name = get_gen_region(network, gen_name)\n",
    "    if region_name not in ror_region_p_dict.keys():\n",
    "        ror_region_p_dict[region_name] = network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom\n",
    "    else:\n",
    "        ror_region_p_dict[region_name] += network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) Find Wind production for\n",
    "wind_names = network.generators_t.p_max_pu.columns[network.generators_t.p_max_pu.columns.str.contains('Wind Generator')].to_list()\n",
    "\n",
    "wind_region_p_dict = {}\n",
    "for gen_name in wind_names :\n",
    "    region_name = get_gen_region(network, gen_name)\n",
    "    if region_name not in wind_region_p_dict.keys():\n",
    "        wind_region_p_dict[region_name] = network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom\n",
    "    else:\n",
    "        wind_region_p_dict[region_name] += network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4) Solar production\n",
    "pv_names = network.generators_t.p_max_pu.columns[network.generators_t.p_max_pu.columns.str.contains('Solar Generator')].to_list()\n",
    "\n",
    "pv_region_p_dict = {}\n",
    "for gen_name in pv_names :\n",
    "    region_name = get_gen_region(network, gen_name)\n",
    "    if region_name not in pv_region_p_dict.keys():\n",
    "        pv_region_p_dict[region_name] = network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom\n",
    "    else:\n",
    "        pv_region_p_dict[region_name] += network.generators_t.p_max_pu[gen_name].apply(lambda x: abs(x)) * network.generators.loc[gen_name].p_nom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (5) TPP Production\n",
    "# NG_CC Link, NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_load = network.loads_t.p_set.sum(axis=1)\n",
    "legend_labels = []\n",
    "prod_list = []\n",
    "# Prepare plotting data\n",
    "# (i) Reservoir\n",
    "for key,values in res_region_p_dict.items():\n",
    "    if values.sum() > 0:\n",
    "        legend_labels.append(key + \" Hydro Reservoir\")\n",
    "        prod_list.append(values)\n",
    "\n",
    "# (ii) RoR\n",
    "for key,values in ror_region_p_dict.items():\n",
    "    if values.sum() > 0:\n",
    "        legend_labels.append(key + \" Hydro RoR\")\n",
    "        prod_list.append(values)\n",
    "\n",
    "# (iii) Wind\n",
    "for key,values in wind_region_p_dict.items():\n",
    "    if values.sum() > 0:\n",
    "        legend_labels.append(key + \" Wind\")\n",
    "        prod_list.append(values)\n",
    "\n",
    "\n",
    "# (iv) Solar\n",
    "for key,values in pv_region_p_dict.items():\n",
    "    if values.sum() > 0:\n",
    "        legend_labels.append(key + \" Solar\")\n",
    "        prod_list.append(values)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "fig,\n",
    "ax.stackplot(prod_list[0].index, prod_list, labels=legend_labels)\n",
    "ax.plot(sys_load,color='red',label='System Load',linestyle='--',linewidth=2)\n",
    "\n",
    "\n",
    "date_format = mdates.DateFormatter('%H:00')  # Define the desired date format\n",
    "ax.xaxis.set_major_formatter(date_format)\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=2)) \n",
    "plt.xticks(rotation=45)  # Rotate the tick labels by 45 degrees\n",
    "plt.ylabel('Power Production (MW)')\n",
    "plt.xlabel('Time Period (Hours)')\n",
    "plt.title(\"Simulated Dispatch for October 30th 2021\")\n",
    "\n",
    "# plt.title(\"Simulated Dispatch for January 1st 2021\")\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_sys_prod(p_dict):\n",
    "    for idx,values in enumerate(p_dict.values()):\n",
    "        if idx == 0:\n",
    "            tot = values.copy()\n",
    "        else:\n",
    "            tot += values.copy()\n",
    "    return tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_load = network.loads_t.p_set.sum(axis=1)\n",
    "legend_labels = []\n",
    "prod_list = []\n",
    "\n",
    "# Prepare plotting data\n",
    "# (i) Reservoir\n",
    "prod_list.append(agg_sys_prod(res_region_p_dict))\n",
    "legend_labels.append('Hydro Reservoir')\n",
    "\n",
    "# (ii) RoR\n",
    "prod_list.append(agg_sys_prod(ror_region_p_dict))\n",
    "legend_labels.append(\"Hydro RoR\")\n",
    "\n",
    "\n",
    "# (iii) Wind\n",
    "prod_list.append(agg_sys_prod(wind_region_p_dict))\n",
    "legend_labels.append(\"Wind\")\n",
    "\n",
    "# (iv) Solar\n",
    "prod_list.append(agg_sys_prod(pv_region_p_dict))\n",
    "legend_labels.append(\"PV\")\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.stackplot(prod_list[0].index, prod_list, labels=legend_labels, colors=['blue', 'cyan','green','yellow'])\n",
    "ax.plot(sys_load,color='red',label='System Load',linestyle='--',linewidth=2)\n",
    "\n",
    "\n",
    "date_format = mdates.DateFormatter('%H:00')  # Define the desired date format\n",
    "ax.xaxis.set_major_formatter(date_format)\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=2)) \n",
    "plt.xticks(rotation=45)  # Rotate the tick labels by 45 degrees\n",
    "plt.ylabel('Power Production (MW)')\n",
    "plt.xlabel('Time Period (Hours)')\n",
    "plt.title(\"Simulated Dispatch for October 30th 2021\")\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/hourly_res.csv\"\n",
    "csmi_path = r\"/home/pmcwhannel/repos/PyPSA_BC/results/hourly_csmi.csv\"\n",
    "\n",
    "res = pd.read_csv(res_path,index_col=0,parse_dates=True) / 1000\n",
    "csmi = pd.read_csv(csmi_path,index_col=0,parse_dates=True) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.sum(axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_list = []\n",
    "legend_labels = []\n",
    "\n",
    "\n",
    "\n",
    "for col in csmi.columns:\n",
    "    load_list.append(csmi[col])\n",
    "    legend_labels.append(col)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.stackplot(range(8760),load_list, labels=legend_labels) #, colors=['blue', 'cyan','green','yellow'])\n",
    "# ax.plot(sys_load,color='red',label='System Load',linestyle='--',linewidth=2)\n",
    "\n",
    "\n",
    "# date_format = mdates.DateFormatter('%H:00')  # Define the desired date format\n",
    "# ax.xaxis.set_major_formatter(date_format)\n",
    "# ax.xaxis.set_major_locator(mdates.HourLocator(interval=2)) \n",
    "# plt.xticks(rotation=45)  # Rotate the tick labels by 45 degrees\n",
    "plt.ylabel('Load (MWh)')\n",
    "plt.xlabel('Time Period (Hours)')\n",
    "plt.title(\"CSMI Hourly Load 2021\")\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_list = []\n",
    "legend_labels = []\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax.stackplot(range(8760),[res.sum(axis=1), csmi.sum(axis=1)], labels=[\"Residential\",\"CSMI\"])\n",
    "# ax.plot(sys_load,color='red',label='System Load',linestyle='--',linewidth=2)\n",
    "\n",
    "\n",
    "# date_format = mdates.DateFormatter('%H:00')  # Define the desired date format\n",
    "# ax.xaxis.set_major_formatter(date_format)\n",
    "# ax.xaxis.set_major_locator(mdates.HourLocator(interval=2)) \n",
    "# plt.xticks(rotation=45)  # Rotate the tick labels by 45 degrees\n",
    "plt.ylabel('Load (MWh)')\n",
    "plt.xlabel('Time Period (Hours)')\n",
    "plt.title(\"Hourly Load 2021\")\n",
    "legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_load = res.sum(axis=0) + csmi.sum(axis=0)\n",
    "norm_res = res.sum(axis=0) / tot_load\n",
    "norm_csmi = csmi.sum(axis=0) / tot_load\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.bar(norm_res.index, norm_res, width=0.6, label='Residential')\n",
    "plt.bar(norm_csmi.index, norm_csmi, width=0.6, bottom=norm_res, label='CSMI')\n",
    "plt.xticks(rotation=-80)\n",
    "plt.title(\"Load Proportion by Region\")\n",
    "plt.legend()\n",
    "# legend = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = r\"/home/pmcwhannel/repos/PyPSA_BC/config/config.yaml\"\n",
    "cfg = utils.load_config(config_file)\n",
    "network_path = \"/home/pmcwhannel/repos/PyPSA_BC/results/network_debug.nc\" # cfg['pypsa']['results']\n",
    "\n",
    "n = pypsa.Network(override_component_attrs=utils.get_multi_link_override())\n",
    "pypsa.Network.import_from_netcdf(network=n, path=network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.generators[n.generators.index == \"BC_WDN_RES Inflow Generator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.generators_t.p_set[\"BC_WDN_RES Inflow Generator\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1948.5 * 1.4695561605876934 * 24 * 90 / 8.760000e09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.buses[n.buses.index == 'Columbia-Shuswap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.links[n.links.index == 'BC_WDN_GSS Spill Link']['efficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.generators[n.generators.index == \"BC_KMO_GSS RoR Generator\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = n.optimize.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.remove_constraints(\"Kirchhoff-Voltage-Law\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.buses[n.buses.index == \"Stikine\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for bus in n.loads.bus:\n",
    "    count += (n.buses.index == \"Alberni-Clayoquot\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.buses[n.buses.index == 'BC_SON_RES Water Bus']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = r\"/home/pmcwhannel/repos/PyPSA_BC/config/config.yaml\"\n",
    "cfg = utils.load_config(config_file)\n",
    "network_path = \"/home/pmcwhannel/repos/PyPSA_BC/results/network_debug.nc\" # cfg['pypsa']['results']\n",
    "\n",
    "n = pypsa.Network(override_component_attrs=utils.get_multi_link_override())\n",
    "pypsa.Network.import_from_netcdf(network=n,path=network_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.links[n.links.carrier == \"Water\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.optimize.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.model.constraints[\"Link-fix-p-lower\"]   #.Constraint(\"2021-01-01 00:00:00, BC_ALH_GSS Store Link\")#[\"Link-fix-p-lower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.links[n.links['bus0'].str.contains(\"WGS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(n.model.constraints.labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.links_t.p2.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.links.p_nom_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bc-power",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "723a4b3183c6d0e7584bbc3f901501adbc978a76a6ba01ecb9d61633ac7850fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
