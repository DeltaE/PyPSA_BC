{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_lines(df_lines_bc):\n",
    "    '''\n",
    "    This function adds lines to the dataset which are missing.\n",
    "    df_lines_bc: Dataframe of the transmission lines in BC.\n",
    "    '''\n",
    "    # (1) Add line connecting BC_WAX_GSS to BC_SEL_TSS\n",
    "    mask = df_lines_bc[\"transmission_line_id\"] == 14552 \n",
    "    drop_cols = ['transmission_line_id', 'line_length_km', 'line_segment_length_km',\n",
    "                'line_segment_length_mi', 'line_length_mi', 'starting_node_name',\n",
    "                'starting_node_code','ending_node_name', 'ending_node_code']\n",
    "    # data_dict = {k:v[0] for k,v in df_lines_bc[mask].drop(drop_cols,axis=1).to_dict(orient='list').items()}\n",
    "    data_dict = df_lines_bc[mask].drop(drop_cols,axis=1).to_dict(orient='list')\n",
    "    data_dict['transmission_line_id'] = [14552999]\n",
    "    data_dict['line_length_km'] = [10]\n",
    "    data_dict['line_segment_length_km'] = [10]\n",
    "    data_dict['starting_node_code'] = [\"BC_WAX_GSS\"]\n",
    "    data_dict['ending_node_code'] = [\"BC_SEL_TSS\"]\n",
    "\n",
    "    return pd.concat([df_lines_bc, pd.DataFrame(data_dict)]).reset_index()\n",
    "\n",
    "def correct_line_node_name(df_lines):\n",
    "    ''' \n",
    "    This function corrects nodes in the lines dataset from CODERS which were improperly named.\n",
    "    '''\n",
    "    \n",
    "    node_cols = [\"starting_node_code\", \"ending_node_code\"]\n",
    "    old_2_new = {\"BC_WHO_JCT\":\"BC_WAH_JCT\",\n",
    "                 \"BC_GST_JCT\":\"BC_MCK_JCT\",\n",
    "                 \"BC_VSY_JCT\":\"BC_NOR_DSS\"}\n",
    "    for col in node_cols:\n",
    "        for old_node,new_node in old_2_new.items():\n",
    "            df_lines.loc[df_lines[col] == old_node, col] = new_node\n",
    "\n",
    "def check_missing_buses(df_sub_bc, df_lines_bc):\n",
    "    '''\n",
    "    Checks for substations which are missing from the lines dataset.\n",
    "    The only bus like this for BC is BC_WAX_GSS which should be connceted to BC_WAN.\n",
    "    df_buses_bc: DF being prepared for saving and loading into PyPSA.\n",
    "    df_sub_bc: DF from CODERS of all substations.\n",
    "    '''\n",
    "    # Checking to BC_WAX_GSS is the only one missing\n",
    "    sub_unique_codes = df_sub_bc[\"node_code\"].apply(lambda x: x.split('_')[1].strip(' ')).unique().tolist()\n",
    "    line_unique_codes_start = df_lines_bc[\"starting_node_code\"].apply(lambda x: x.split('_')[1].strip(' ')).unique().tolist()\n",
    "    line_unique_codes_end = df_lines_bc[\"ending_node_code\"].apply(lambda x: x.split('_')[1].strip(' ')).unique().tolist()\n",
    "    line_unique_codes = list(set(line_unique_codes_start + line_unique_codes_end))\n",
    "\n",
    "    for code in sub_unique_codes:\n",
    "        if code not in line_unique_codes:\n",
    "            print(f\"the code {code} is missing from the lines dataset!\") # to be logged\n",
    "\n",
    "def add_pypsa_columns_2_line_df(df):\n",
    "    ''' \n",
    "    This function will add the columns to the line df which will be imported into a pypsa network.\n",
    "    line names assigned according to standard of voltage (i.e. 230_AAL, 230 = 230kV and AAL = middle 3 char of node_code).\n",
    "    Line parameters such as reactance and resistance are imputed based on line type.\n",
    "    name: Name of the transmission line, formatted as the starting and ending node code appended together. (i.e. XXX_GSS_YYY_DSS)\n",
    "    type: Voltage level of the transmission line (i.e. 230kV).\n",
    "    bus0: Name of the starting bus.\n",
    "    bus1: Name of the ending bus.\n",
    "    v_nom: Nominal voltage level (i.e. 230).\n",
    "\n",
    "    '''\n",
    "    name = []\n",
    "    type = []\n",
    "    bus0 = []\n",
    "    bus1 = []\n",
    "    length = []\n",
    "    v_nom = []\n",
    "\n",
    "    for idx,line in df.iterrows():\n",
    "        voltage_type = f'{str(int(line[\"voltage_in_kv\"]))}kV'\n",
    "        name.append(line[\"starting_node_code\"][3:] + line[\"ending_node_code\"][2:])\n",
    "        type.append(voltage_type)\n",
    "        bus0.append(voltage_type.rstrip('kV') + \"_\" + line['starting_node_code'].split('_')[1] + \"_\" + line['starting_node_code'].split('_')[2])\n",
    "        bus1.append(voltage_type.rstrip('kV') + \"_\" + line['ending_node_code'].split('_')[1] + \"_\" + line['ending_node_code'].split('_')[2])\n",
    "        length.append(line[\"line_segment_length_km\"])\n",
    "        v_nom.append(line[\"voltage_in_kv\"])\n",
    "\n",
    "    df['name'] = name\n",
    "    df['type'] = type\n",
    "    df['bus0'] = bus0\n",
    "    df['bus1'] = bus1\n",
    "    df['length'] = length\n",
    "    df['v_nom'] = v_nom\n",
    "\n",
    "def create_bus_df(df_lines, df_substations):\n",
    "    '''\n",
    "    This function will create an initial DataFrame of buses for PyPSA_BC from a DataFrame of lines.\n",
    "    When creating the buses it\n",
    "    The lines DF contains the node names for the buses, nomial voltage, and the carrier is implicitly added.\n",
    "    '''\n",
    "    # name = []\n",
    "    # x = []\n",
    "    # y = []\n",
    "    # type = []\n",
    "    # v_nom = []\n",
    "    data_dict = {}\n",
    "\n",
    "    # (1) Add buses based on line nodes\n",
    "    for idx,line in df_lines.iterrows():\n",
    "        # Search for match between line and substation\n",
    "        for node_code in [line[\"starting_node_code\"], line[\"ending_node_code\"]]:\n",
    "            bus_name, bus_x, bus_y = get_bus_name_x_y(line, node_code, df_substations)\n",
    "            if bus_name not in data_dict: # Avoid duplication (Change to dictionary)\n",
    "                data_dict[bus_name] = {'x':bus_x, 'y':bus_y, 'type':line['type'], 'v_nom':line['v_nom']}\n",
    "                # name.append(bus_name) # i.e. 230_AAL\n",
    "                # x.append(bus_x)\n",
    "                # y.append(bus_y)\n",
    "                # type.append(line['type'])\n",
    "                # v_nom.append(line['v_nom'])\n",
    "    \n",
    "    df_buses = pd.DataFrame.from_dict(data_dict,orient='index').reset_index().rename(columns={'index':'name'})\n",
    "    # df_buses = pd.DataFrame()\n",
    "    # df_buses = pd.DataFrame()\n",
    "    # df_buses['name'] = name\n",
    "    # df_buses['x'] = x\n",
    "    # df_buses['y'] = y\n",
    "    # df_buses['type'] = type\n",
    "    # df_buses['v_nom'] = v_nom\n",
    "\n",
    "    return df_buses\n",
    "\n",
    "def get_bus_name_x_y(line, node_code, df_substations):\n",
    "    '''\n",
    "    This function finds the correct name for a bus from the node dataset\n",
    "    line: Line row from CODERS lines dataframe.\n",
    "    node_code: Name of start/end node from CODERS lines dataframe.\n",
    "    df_substations: Substations dataframe from CODERS.\n",
    "    return bus_name: Unique name to use for the bus in PyPSA (i.e. 230_AAL_DSS, 230=nominal_voltage, AAL=unique substation name in CODERS, DSS=Substation type)\n",
    "    return bus_x: Bus longitude. \n",
    "    return bus_y: Bus latitude.\n",
    "    '''\n",
    "    # (1) identical match\n",
    "    for idx,substation in df_substations.iterrows():\n",
    "        if substation[\"node_code\"] == node_code:\n",
    "            bus_name = str(line[\"v_nom\"]) + \"_\" + \"_\".join(node_code.split('_')[1:]) # (i.e. 230_AAL_DSS)\n",
    "            bus_x = substation[\"longitude\"]\n",
    "            bus_y = substation[\"latitude\"]\n",
    "            return bus_name, bus_x, bus_y\n",
    "\n",
    "    # print(f\"Did not find exact match for line node: {node_code}\") # To-be logged\n",
    "\n",
    "    # (2) International and Interprovincial nodes\n",
    "    if node_code.split('_')[-1] in [\"IPT\",\"INT\"]:\n",
    "        bus_name = str(line[\"v_nom\"]) + \"_\" + \"_\".join(node_code.split('_')[1:])\n",
    "        if node_code == \"PP_BCAB3_IPT\":\n",
    "            # ~ 50 km east\n",
    "            bus_y, bus_x = 50.247937, -114.2 \n",
    "        elif node_code == \"PP_BCAB1_IPT\":\n",
    "            # ~ 18 km east\n",
    "            bus_y, bus_x = 49.735535, -114.6\n",
    "        elif node_code == \"PP_BCAB4_IPT\":\n",
    "            # ~21 km east\n",
    "            bus_y, bus_x = 58.64525, -119.7\n",
    "        elif node_code == \"XX_BCUS2_INT\":\n",
    "            # ~ 1 km south\n",
    "            bus_y, bus_x = 48.9974, -117.341514\n",
    "        elif node_code == \"XX_BCUS1_INT\":\n",
    "            # ~ 21 km south\n",
    "            bus_y, bus_x = 48.97 , -122.873948\n",
    "        elif node_code == \"PP_BCAB2_IPT\":\n",
    "            # ~ 108 km east\n",
    "            bus_y, bus_x = 49.500543, -114.08\n",
    "        return bus_name, bus_x, bus_y\n",
    "\n",
    "    # (3) Find first matching 3-middle characters\n",
    "    for idx,substation in df_substations.iterrows():\n",
    "        if node_code.split('_')[1] == substation['node_code'].split('_')[1]:\n",
    "            bus_name = str(line[\"v_nom\"]) + \"_\" + \"_\".join(node_code.split('_')[1:])\n",
    "            bus_x = substation[\"longitude\"]\n",
    "            bus_y = substation[\"latitude\"]\n",
    "            return bus_name, bus_x, bus_y\n",
    "    # print(f\"Did not find partial match for: {node_code}\") # To-be logged\n",
    "\n",
    "    # (4) No matching 3 middle characters (i.e. BC_WAX_GSS).. these are special cases..\n",
    "    print(f\"There is no information to create bus for: {node_code}\") # To-be logged\n",
    "\n",
    "    return None,None,None\n",
    "\n",
    "def create_line_types_df(df_lines, df_line_table):\n",
    "    '''\n",
    "    This function adds line type information for each line.\n",
    "    Assuming all lines can have their transmission inferred on the basis of ampacity alone...\n",
    "    # eventually will need a calculator based on short, medium, or long and voltage.\n",
    "    r: resistance per length (Ohm per km)\n",
    "    x: resistance/reactance per length (Ohm per km)\n",
    "    c: shunt capacitance per length (nF per km)\n",
    "    i: Nominal current (kA)\n",
    "    cc: Cross section (mm^2)\n",
    "    1) match based on closest match in the table\n",
    "    2) match based on average for similar lines???\n",
    "    '''\n",
    "    ampacity_sel_col = \"summer_ampacity\"\n",
    "    f_nom = 60 # nominal frequency in NA is 60 Hz\n",
    "    data_dict = {'name':[],\n",
    "                'f_nom':[],\n",
    "                'r_per_length':[],\n",
    "                'x_per_length':[],\n",
    "                'c_per_length':[],\n",
    "                'i_nom':[],\n",
    "                'mounting':[],\n",
    "                'cross_section':[]}\n",
    "    line_type_col = []\n",
    "    amp_cap_2_idx = {amp_cap:idx for idx,amp_cap in enumerate(df_line_table[\"approx_current_capacity\"])}\n",
    "\n",
    "    for _,row in df_lines.iterrows():\n",
    "        ampacity = row[ampacity_sel_col] # Later should look into making this based on a timeseries.\n",
    "        if not math.isnan(ampacity):\n",
    "            name = str(int(ampacity)) \n",
    "            line_type_col.append(name) # Add line type for matching within PyPSA.\n",
    "\n",
    "            if name not in data_dict[\"name\"]:\n",
    "                idx = sorted([(abs(amp_cap-ampacity), idx) for amp_cap,idx in amp_cap_2_idx.items()])[0][-1] # Find row index for closest ampacity in the table.\n",
    "                data_dict[\"name\"].append(name) # More descriptive name later (ampacity for now).\n",
    "                data_dict[\"f_nom\"].append(f_nom) # Hz\n",
    "                data_dict['r_per_length'].append(df_line_table[\"resistance_ac_25_deg\"].iloc[idx] / 1000)\n",
    "                data_dict['x_per_length'].append(df_line_table[\"x_l\"].iloc[idx])\n",
    "                data_dict['c_per_length'].append(8.85) # Assumed based on VI-PyPSA.. Needs updating..\n",
    "                data_dict['i_nom'].append(df_line_table[\"resistance_ac_25_deg\"].iloc[idx] / 1000)\n",
    "                data_dict['mounting'].append(\"ol\")\n",
    "                data_dict['cross_section'].append(df_line_table[\"cross_section_mm2\"].iloc[idx] )\n",
    "\n",
    "            else:\n",
    "                continue # already have this line type added\n",
    "        else:\n",
    "            # use mode ampacity for same voltage type \n",
    "            if row[\"voltage_in_kv\"] == 63: # replace 63 kV since no ampacity on it\n",
    "                voltage = 69 \n",
    "            elif row[\"voltage_in_kv\"] == 161: # replace 161 kV since no ampacity for it\n",
    "                voltage = 138 \n",
    "            else:\n",
    "                voltage = row[\"voltage_in_kv\"]\n",
    "\n",
    "            ampacity = df_lines[(df_lines[\"voltage_in_kv\"] == voltage) & (~df_lines[\"summer_ampacity\"].isnull())][\"summer_ampacity\"].mode()[0]\n",
    "                \n",
    "            line_type_col.append(str(int(ampacity)))\n",
    "\n",
    "    df_lines[\"type\"] = line_type_col\n",
    "    df_line_types = pd.DataFrame(data_dict)\n",
    "\n",
    "    return df_line_types\n",
    "\n",
    "def rename_duplicate_lines(df_lines_bc):\n",
    "    '''\n",
    "    Renamed duplicate lines, adding _# to reach in order found.\n",
    "    '''\n",
    "    indices = df_lines_bc[df_lines_bc.duplicated(subset=[\"name\"],keep=False)].index.tolist()\n",
    "    print(indices)\n",
    "    name_dict = {} # keep record of modifications\n",
    "    for index in indices:\n",
    "        name = df_lines_bc.loc[index,\"name\"]\n",
    "        if name not in name_dict.keys():      \n",
    "            name_dict[name] = 1\n",
    "        else:\n",
    "            name_dict[name] += 1\n",
    "        df_lines_bc.loc[index,\"name\"] = name + \"_\" + str(name_dict[name])\n",
    "\n",
    "def add_line_op_params(df_lines_bc, df_line_types_bc):\n",
    "    '''\n",
    "    This function add operational parameters to the lines such as:\n",
    "    s_nom = which is pulled from \n",
    "    '''\n",
    "    df_lines_bc['s_nom'] = df_lines_bc.apply(lambda line: add_line_s_nom(line),axis=1)\n",
    "\n",
    "def add_line_s_nom(line):\n",
    "    '''\n",
    "    This function is applied row-wise to calculate the s_nom (MVA) for each line.\n",
    "    Using data from CODERS to impute the s_nom value for lines as follows:\n",
    "    rule 1: use summer_rating_in_mva\n",
    "    rule 2: use summer_capacity_in_mw adjusted by a power factor = 0.9\n",
    "    Using the summer values is a pessimistic assumption for other seasons.\n",
    "    '''\n",
    "    if line['summer_rating_in_mva'] == 0:\n",
    "        s_nom = round(line['summer_capacity_in_mw'] / 0.9, 4) # (assumed 0.9 power factor + rounded to 4th decimal)\n",
    "    else:\n",
    "        s_nom = line['summer_rating_in_mva']\n",
    "\n",
    "    return s_nom\n",
    "\n",
    "\n",
    "def create_transformer_df(df_buses):\n",
    "    '''\n",
    "    This function creates a dataframe of transformers based on buses with multiple voltages.\n",
    "    Voltages attached incrementally from low to highest at a given bus.\n",
    "    Transformers are each given as a standardized type.\n",
    "    df_buses: Dataframe of PyPSA formatted buses.\n",
    "    '''\n",
    "    # Find unique buses and their indices\n",
    "    bus_dict = {}\n",
    "    for idx,row in df_buses.iterrows():\n",
    "        key = \"_\".join(row['name'].split('_')[1:]) # i.e. VIT_TSS\n",
    "        if key not in bus_dict.keys():\n",
    "            bus_dict[key] = [row['v_nom']]\n",
    "        else:\n",
    "            bus_dict[key].append(row['v_nom'])\n",
    "\n",
    "    #\n",
    "    transformers = [] # list to hold transformers to create\n",
    "    for bus,voltages in bus_dict.items():\n",
    "        if len(voltages) <= 1: \n",
    "            continue\n",
    "        else: # More than 1 voltage at the unique bus\n",
    "            N = len(voltages)\n",
    "            voltages_sorted = sorted(voltages)\n",
    "            for idx in range(N-1):\n",
    "                hv = voltages_sorted[idx+1]\n",
    "                lv = voltages_sorted[idx]\n",
    "                bus0 =  str(hv) + \"_\" + bus\n",
    "                bus1 =  str(lv) + \"_\" + bus\n",
    "                type = f\"{hv}/{lv}\"\n",
    "                transformer_name = f'{bus}_{hv}_{lv}'\n",
    "                transformers.append([transformer_name,\n",
    "                                    bus0,\n",
    "                                    bus1,\n",
    "                                    type]\n",
    "                                    )\n",
    "\n",
    "    df_transformers = pd.DataFrame(transformers, columns = ['name','bus0','bus1','type'])\n",
    "\n",
    "    return df_transformers\n",
    "    \n",
    "def create_tranformer_types_df(df_transformers):\n",
    "    '''\n",
    "    This function will create transformers for typical hv to lv lines.\n",
    "    Assumption 1: All buses use standardized transformers and \n",
    "    there is only 1 type for each unique tuple of high and low voltage.\n",
    "    Assumption 2: The capacity (MVA) of the transformer is not a bottleneck of the system,\n",
    "    therefore, the capacity (s_nom) is set to be 2000 MVA (assumed limitless).\n",
    "    Assumption 3: All transformers have the same parameters. (UPDATE LATER) \n",
    "    '''\n",
    "    data = []\n",
    "    for idx,row in df_transformers.iterrows():\n",
    "        hv = int(row['type'].split('/')[0])\n",
    "        lv = int(row['type'].split('/')[1])\n",
    "        name = row['type']\n",
    "        f_nom = 60\n",
    "        s_nom = 2000\n",
    "        v_nom_0 = hv\n",
    "        v_nom_1 = lv\n",
    "        vsc = 10 # Update\n",
    "        vscr = 0.3 # Update\n",
    "        pfe= 30 # Update\n",
    "        i0 = 0.04 #2-10%\n",
    "        phase_shift = 150 \n",
    "        tap_side = 0\n",
    "        tap_neutral = 0\n",
    "        tap_min = -9\n",
    "        tap_max = 9\n",
    "        tap_step = 1.5\n",
    "\n",
    "        data.append([name,f_nom,s_nom,v_nom_0,v_nom_1,\n",
    "                    vsc,vscr,pfe,i0,phase_shift,tap_side,\n",
    "                    tap_neutral,tap_min,tap_max,tap_step])\n",
    "\n",
    "    df_transformer_types = pd.DataFrame(data,columns=[\"name\",\"f_nom\",\"s_nom\",\n",
    "                               \"v_nom_0\",\"v_nom_1\", \"vsc\",\n",
    "                               \"vscr\",\"pfe\",\"i0\",\"phase_shift\",\n",
    "                               \"tap_side\",\"tap_neutral\",\"tap_min\",\n",
    "                               \"tap_max\",\"tap_step\"]).drop_duplicates()\n",
    "\n",
    "    return df_transformer_types\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# /mnt/c/Users/pmcw9/Delta-E/PICS/Data\n",
    "transmission_line_path = r\"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/SESIT/CODERS/data-pull/network/transmission_lines.csv\"\n",
    "substations_path = r\"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/SESIT/CODERS/data-pull/network/substations.csv\"\n",
    "transmission_line_type_table = r\"/mnt/c/Users/pmcw9/Delta-E/PICS/Data/custom/electric_power_generation_table_13_3a.xlsx\"\n",
    "\n",
    "df_lines = pd.read_csv(transmission_line_path)\n",
    "df_substations = pd.read_csv(substations_path)\n",
    "df_line_table = pd.read_excel(transmission_line_type_table) # Tables with line type data for indexing by ampacities\n",
    "\n",
    "df_sub_bc = df_substations[df_substations[\"province\"] == \"BC\"].copy()\n",
    "df_lines_bc = df_lines[df_lines[\"province\"] == \"BC\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 15, 16, 19, 20, 22, 35, 36, 54, 55, 62, 63, 65, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 85, 86, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 113, 114, 118, 120, 124, 129, 140, 141, 145, 147, 148, 155, 162, 163, 167, 168, 170, 176, 202, 203, 261, 263, 281, 282, 302, 303, 345, 353, 356, 357, 360, 361, 362, 372, 380, 381, 384, 386, 398, 400, 402, 404, 405, 407, 408, 409, 411, 413, 414, 415, 424, 425, 426, 427, 439, 441, 442, 443, 444, 445, 446, 447, 448, 450, 451, 452, 460, 461, 462, 465, 466, 473, 474, 494, 496, 501, 502, 517, 518, 519, 520, 521, 524, 525, 527, 528, 529, 530, 531, 532, 533, 540, 541, 545, 546, 547, 548, 549, 550, 552, 553, 560, 562, 564, 565, 566, 567, 572, 573, 574, 575, 576, 577, 578, 579, 589, 592, 593, 598, 599, 609, 610, 614, 615, 616, 628, 630, 642, 643, 644, 646, 651, 652, 653, 655, 656, 657, 661, 662, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 689, 697, 698, 699, 711, 712, 713, 714, 730, 738, 739, 740, 752, 753, 754, 756, 757, 758, 759, 761, 762, 764, 765, 767, 772, 773, 777, 778, 783, 785, 808, 811, 854, 857, 935, 950, 951, 953, 954, 958, 959, 963, 964, 979, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1065, 1067, 1074, 1075, 1076, 1077, 1078, 1079, 1119, 1120, 1132, 1133, 1135, 1136, 1139, 1140, 1141]\n"
     ]
    }
   ],
   "source": [
    "# BC_WAX_GSS is only substation which is not in the line dataset. \n",
    "# I will need to look into implications of this when supply connected.\n",
    "\n",
    "# (0) Replace NaN for summer rating with 0\n",
    "df_lines_bc['summer_rating_in_mva'] = df_lines_bc[\"summer_rating_in_mva\"].fillna(0.)\n",
    "\n",
    "# (1) Correction to data\n",
    "correct_line_node_name(df_lines_bc) \n",
    "\n",
    "# (2) Remove spaces from code names\n",
    "df_sub_bc[\"node_code\"] = df_sub_bc[\"node_code\"].apply(lambda x: x.replace(\" \",\"\"))\n",
    "df_lines_bc[\"starting_node_code\"] = df_lines_bc[\"starting_node_code\"].apply(lambda x: x.replace(\" \",\"\"))\n",
    "df_lines_bc[\"ending_node_code\"] = df_lines_bc[\"ending_node_code\"].apply(lambda x: x.replace(\" \",\"\"))\n",
    "\n",
    "# (3) Add missing lines to dataset\n",
    "bc_lines = add_missing_lines(df_lines_bc)\n",
    "\n",
    "# (4) Enrich coders dataframe of BC lines with columns used by PyPSA \n",
    "add_pypsa_columns_2_line_df(bc_lines)\n",
    "\n",
    "# # (5) Create dataframe of BC buses from the lines and substations\n",
    "df_buses_bc = create_bus_df(bc_lines, df_sub_bc) \n",
    "check_missing_buses(df_sub_bc, bc_lines)\n",
    "\n",
    "# # (6) create dataframe of line types for BC\n",
    "bc_line_types = create_line_types_df(bc_lines, df_line_table)\n",
    "\n",
    "# # (7) rename lines which are duplicates (add suffix of _#)\n",
    "rename_duplicate_lines(bc_lines)\n",
    "\n",
    "# # (8) add all needed operational parameters to lines\n",
    "add_line_op_params(bc_lines, bc_line_types)\n",
    "\n",
    "# # (9) create dataframe of transformers for BC\n",
    "df_transformers_bc = create_transformer_df(df_buses_bc)\n",
    "\n",
    "# # (10) create dataframe of transformer types for BC\n",
    "df_transformer_types_bc = create_tranformer_types_df(df_transformers_bc)\n",
    "\n",
    "# ## Additional attributes\n",
    "df_buses_bc['substation_type'] = df_buses_bc['name'].apply(lambda x: x.split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to folder\n",
    "# 138_KWL_GSS missing from buses dataframe\n",
    "path = r\"C:\\Users\\pmcw9\\Delta-E\\PICS\\PyPSA_BC\\results\\pypsa-network\"\n",
    "\n",
    "bc_lines.to_csv(path + \"\\\\lines.csv\", index=False, columns=['name','type','bus0','bus1','length','v_nom','s_nom'])\n",
    "df_buses_bc.to_csv(path + \"\\\\buses.csv\", index=False)\n",
    "bc_line_types.to_csv(path + \"\\\\line_types.csv\", index=False)\n",
    "df_transformers_bc.to_csv(path + \"\\\\transformers.csv\", index=False)\n",
    "df_transformer_types_bc.to_csv(path + \"\\\\transformer_types.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave = False\n",
    "# for idx,line in df_lines_bc.iterrows():\n",
    "#     type = line['type']\n",
    "#     line_type_matched = df_line_types_bc[df_line_types_bc['name'] == type]\n",
    "#     if line_type_matched.shape[0] != 1:\n",
    "#         print('Error incorrect number of matches for line types.')\n",
    "#         break\n",
    "#     i_nom = line_type_matched['i_nom'].iloc[0]\n",
    "#     option_1 = i_nom * line['v_nom']\n",
    "#     option_2 = option_1 * line['length']\n",
    "#     if line['summer_rating_in_mva'] == 0:\n",
    "#         option_3 = round(line['summer_capacity_in_mw'] / 0.9, 4) # (assumed 0.9 power factor + rounded to 4th decimal)\n",
    "#     else:\n",
    "#         option_3 = line['summer_rating_in_mva']\n",
    "#         leave = True\n",
    "#     print('-------------------------') \n",
    "#     print(f'The estimated s_nom (MVA) based on i_nom * v_nom = {option_1} MVA')\n",
    "#     print(f'The estimated s_nom (MVA) based on i_nom * v_nom * length = {option_2} MVA')\n",
    "#     print(f'The estimated s_nom (MVA) based on CODERS is {option_3} MVA')\n",
    "\n",
    "#     if leave:\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pypsa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ea52cced35c77daeb96cd6b5ef20fc9ffe90b4d385d86dc1838d5d4232b92718"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
